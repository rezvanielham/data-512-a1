{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Curation on English Wikipedia View Metrics\n",
    "\n",
    "The goal of this notebook is to provide reproducable steps into the analysis of view metrics data provided by wikimedia foundation.\n",
    "* Note:please see the Licensing details on the repository ReadMe for more details about terms of use.\n",
    "\n",
    "In this analysis we will collect and analyze the monthly traffic metric data in the time window of January 1 2008 through September 30 2017 on English Wikipedia from two different source API servers:\n",
    "\n",
    "- Legacy service a.k.a the legacy Pagecounts API ( [documentation] (https://wikitech.wikimedia.org/wiki/Analytics/AQS/Legacy_Pagecounts), [endpoint] (https://wikimedia.org/api/rest_v1/#!/Pagecounts_data_(legacy)/get_metrics_legacy_pagecounts_aggregate_project_access_site_granularity_start_end)) provides access to desktop and mobile traffic data from January 2008 through July 2016. \n",
    "\n",
    "- Current service a.k.a The Pageviews API ([documentation] (https://wikitech.wikimedia.org/wiki/Analytics/AQS/Pageviews), [endpoint] (https://wikimedia.org/api/rest_v1/#!/Pageviews_data/get_metrics_pageviews_aggregate_project_access_agent_granularity_start_end)) provides access to desktop, mobile web, and mobile app traffic data from July 2015 through September 2017.\n",
    "\n",
    "The following sections will include steps from data-acquisition, processing and finally analysis.\n",
    "\n",
    "\n",
    "### Step I: Data Acquisition\n",
    "\n",
    "In this section we are collecting data from both APIs and saving the results in 5 separate JSON formatted files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named matplotlib",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-a351f8926d3a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'matplotlib'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'inline'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\python27\\lib\\site-packages\\IPython\\core\\interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_line_magic\u001b[1;34m(self, magic_name, line)\u001b[0m\n\u001b[0;32m   2079\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'local_ns'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2080\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2081\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2082\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<decorator-gen-106>\u001b[0m in \u001b[0;36mmatplotlib\u001b[1;34m(self, line)\u001b[0m\n",
      "\u001b[1;32mc:\\python27\\lib\\site-packages\\IPython\\core\\magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 188\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python27\\lib\\site-packages\\IPython\\core\\magics\\pylab.pyc\u001b[0m in \u001b[0;36mmatplotlib\u001b[1;34m(self, line)\u001b[0m\n\u001b[0;32m     98\u001b[0m             \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Available matplotlib backends: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mbackends_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m             \u001b[0mgui\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_matplotlib\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgui\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_show_matplotlib_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgui\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python27\\lib\\site-packages\\IPython\\core\\interactiveshell.pyc\u001b[0m in \u001b[0;36menable_matplotlib\u001b[1;34m(self, gui)\u001b[0m\n\u001b[0;32m   2936\u001b[0m         \"\"\"\n\u001b[0;32m   2937\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpylabtools\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2938\u001b[1;33m         \u001b[0mgui\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_gui_and_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgui\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpylab_gui_select\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2939\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2940\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mgui\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'inline'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\python27\\lib\\site-packages\\IPython\\core\\pylabtools.pyc\u001b[0m in \u001b[0;36mfind_gui_and_backend\u001b[1;34m(gui, gui_select)\u001b[0m\n\u001b[0;32m    271\u001b[0m     \"\"\"\n\u001b[0;32m    272\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 273\u001b[1;33m     \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    274\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    275\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mgui\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mgui\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'auto'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named matplotlib"
     ]
    }
   ],
   "source": [
    "#coding utf-8\n",
    "\n",
    "import requests\n",
    "import json\n",
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have introduced dictionaries each including constant values that have been provided in the API documentations of current(coded as 'curr') and legacy(coded as 'legacy') API providers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# representing our API sources\n",
    "projects = { 'pageCounts': 'legacy', 'pageViews':'curr'}\n",
    "#endpoints of current and legacy API servers\n",
    "endpoint = {\n",
    "    'curr' :'https://wikimedia.org/api/rest_v1/metrics/pageviews/aggregate/{project}/{access}/{agent}/{granularity}/{start}/{end}',\n",
    "    'legacy' : 'https://wikimedia.org/api/rest_v1/metrics/legacy/pagecounts/aggregate/{project}/{access-site}/{granularity}/{start}/{end}'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each API endpoint can be accessed in multiple ways. In the legacy data, the only distinguished access types were mobile and desktop sites, however after July 2015, in order to distiguish the automated (web-crawler) access from the real-user access mechanisms, the new API provider introduced the 'agent' parameter. Thus by specifying the agent as 'user' we are able to further filter access by users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the available access mechanisms \n",
    "access = {\n",
    "    'curr' : {'desktop', 'mobile-app', 'mobile-web'},\n",
    "    'legacy' : {'desktop-site', 'mobile-site'}\n",
    "}\n",
    "\n",
    "date_range = {\n",
    "    'legacy' : { 'start' : '2008010100', 'end' : '2016080100'},\n",
    "    'curr' : { 'start' : '2015070100','end' : '2017120100'}\n",
    "}\n",
    "\n",
    "#page_count_endpoint = ''\n",
    "headers={'User-Agent' : 'https://github.com/rezvanielham', 'From' : 'rezvanil@uw.edu'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following method constructs a dictionary of parameters based on accesstype, start and end dates and API source.\n",
    "The result of this method will be used to construct the API call URLs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_params(access, start, end, project):\n",
    "\n",
    "    params = dict()\n",
    "\n",
    "    if(project =='curr'):\n",
    "        params['access'] = access\n",
    "        params['agent'] = 'user'\n",
    "    else:\n",
    "        params['access-site'] = access\n",
    "    params['project'] = 'en.wikipedia.org'\n",
    "    params['granularity'] = \"monthly\"\n",
    "    params['start'] = start\n",
    "    params['end'] = end\n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a helper method to format the start and end dates from YYYMMDD format to YYYYMM format by eliding the day value.\n",
    "The result of this method is used later in naming the output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ym_date(ymd_start, ymd_end):\n",
    "    '''\n",
    "\n",
    "    :param ymd_start: the start date with YYYYMMDD format\n",
    "    :param ymd_end: the end date with YYYYMMDD format\n",
    "    :return: the param dict of start and end dates with YYYYMM format removing the rest of the string\n",
    "    '''\n",
    "    params = dict()\n",
    "    params['ym-start'] = ymd_start[0:6]\n",
    "    params['ym-end'] = ymd_end[0:6]\n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method formats the aquired 4-digit YYYYMM based on the project types (because we need different date-ranges given each API source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_view_formatted_dates(project):\n",
    "    return get_ym_date(date_range[project]['start'], date_range[project]['end'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally at this step, we have everything to begin calling into the API endpoints and right the corresponding data to files in this format: \"apiname_accesstype_firstmonth-lastmonth.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for project in projects:\n",
    "   prj = projects[project]\n",
    "   for acs in access[prj]:\n",
    "        api_call = requests.get(endpoint[projects[project]].format(**get_params(acs, \\\n",
    "                                                                                date_range[prj]['start'], \\\n",
    "                                                                                date_range[prj]['end'], \\\n",
    "                                                                                prj)))\n",
    "        response = api_call.json()\n",
    "        #print to files with names with this format:\n",
    "        out_file_name = project + '_{}_{}_{}.json'.format(acs, get_page_view_formatted_dates(prj)['ym-start'],\n",
    "                                                          get_page_view_formatted_dates(prj)['ym-end'])\n",
    "        json.dump(response, open(out_file_name, \"w\"), indent=4\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step II : Data Processing\n",
    "\n",
    "Now that we have collected the data there are a few processing steps before we can run any sort of visualization or analysis on it.\n",
    "\n",
    "#### Page-View Data Processing Steps:\n",
    "a. First step is to combine the mobile-app and mobile-web access type values from PageViews data sets into a single file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "#Step1: load page view mobile-app and mobile-web data into memory to combine both\n",
    "pv_mobile_app_json = json.load(open(r'''pageViews_mobile-app_201507_201712.json'''))\n",
    "pv_mobile_web_json = json.load(open(r'''pageViews_mobile-web_201507_201712.json'''))\n",
    "\n",
    "#Initialize a result set\n",
    "pv_mobile_combined = dict()\n",
    "pv_mobile_combined['items'] = list()\n",
    "\n",
    "for app_item in pv_mobile_app_json['items']:\n",
    "    for web_item in pv_mobile_web_json['items']:\n",
    "        if app_item['timestamp'] == web_item['timestamp']:\n",
    "            app_item['views'] = app_item['views'] + web_item['views']\n",
    "            break\n",
    "    pv_mobile_combined['items'].append(app_item)\n",
    "\n",
    "#Writing the combined result to disk\n",
    "json.dump(pv_mobile_combined, open(r'''pageViews_mobile_combined_201507_201712.json''', \"w\"), indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. As the next step of the processing on Page View data sets, we are going to add the month and year values to the end of each record to prepare for next steps where we want to sum up the total view counts.\n",
    "\n",
    "The below for-loops take care of this requirement for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding year and month columns to the combined mobile data for page views\n",
    "for combined_item in pv_mobile_combined['items']:\n",
    "    combined_item['year'] = combined_item['timestamp'][0:4]\n",
    "    combined_item['month'] = combined_item['timestamp'][4:6]\n",
    "\n",
    "\n",
    "#load page view desktop data into memory to add the month and year columns\n",
    "pv_desktop_json = json.load(open(r'''pageViews_desktop_201507_201712.json'''))\n",
    "for desktop_item in pv_desktop_json['items']:\n",
    "    desktop_item['year'] = desktop_item['timestamp'][0:4]\n",
    "    desktop_item['month'] = desktop_item['timestamp'][4:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c. The final step at this level of processing the page view datasets is to combine everything into a single\n",
    "data structure called: pv_total_views and make it ready for next steps. This new combined dictionary of items will have a new column to represent the summed up value of the total counts for mobile(app-web) and Desktop sites by a 'user' agent:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a list of items with a new column called total_views for page views\n",
    "pv_total_views = dict()\n",
    "pv_total_views['items'] = list()\n",
    "\n",
    "#sum up the values for mobile and desktop for pageview data (adding columns according to the final result format\n",
    "for mobile_item in pv_mobile_combined['items']:\n",
    "    for desktop_item in pv_desktop_json['items']:\n",
    "        if mobile_item['month'] == desktop_item['month'] and mobile_item['year'] == desktop_item['year']:\n",
    "            #add the base item including the monthly view information for desktop first\n",
    "            #we then add the following columns to match the final result format\n",
    "            # 1. pageview_desktop_views columns which has the same value as the exisiting 'views' columns\n",
    "            # 2. pageview_mobile_views which is the value of the 'views' from the corresponding month from mobile data\n",
    "            # 3. pageview_all_views the sum of mobile and desktop views\n",
    "            desktop_item['pageview_desktop_views'] = desktop_item['views']\n",
    "            desktop_item['pageview_mobile_views'] = mobile_item['views']\n",
    "            desktop_item['pageview_all_views'] = desktop_item['views'] + mobile_item['views']\n",
    "            pv_total_views['items'].append(desktop_item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Page-Count Data Processing Steps:\n",
    "\n",
    "a.We are going to repeat the steps of adding month and year columns to page count data sets as well to facilitate the last step of suming of the total view values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load page count mobile into memory to add the year and month columns\n",
    "pc_mobile_json = json.load(open(r'''pageCounts_mobile-site_200801_201608.json'''))\n",
    "for mobile_item in pc_mobile_json['items']:\n",
    "    mobile_item['year'] = mobile_item['timestamp'][0:4]\n",
    "    mobile_item['month'] = mobile_item['timestamp'][4:6]\n",
    "\n",
    "#load page count desktop into memory to add the year and month columns\n",
    "pc_desktop_json = json.load(open(r'''pageCounts_desktop-site_200801_201608.json'''))\n",
    "for desktop_item in pc_desktop_json['items']:\n",
    "    desktop_item['year'] = desktop_item['timestamp'][0:4]\n",
    "    desktop_item['month'] = desktop_item['timestamp'][4:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b. Final step at this level is to combine the total desktop-site and mobile-site view counts and add a column which represents the total-views sum in a new dicts. The below code creates the pc_total_views dictionary with all the neccasary column for the next steps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the final results for page count\n",
    "pc_total_views = dict()\n",
    "pc_total_views['items'] = list()\n",
    "\n",
    "#sum up the values for mobile and desktop for page count data (adding columns according to the final result format\n",
    "for desktop_item in pc_desktop_json['items']:\n",
    "    mobViews = 0\n",
    "    for mobile_item in pc_mobile_json['items']:\n",
    "            if mobile_item['month'] == desktop_item['month'] and mobile_item['year'] == desktop_item['year']:\n",
    "                mobViews = mobile_item['count']\n",
    "    #add the base item including the monthly view information for desktop first\n",
    "    #we then add the following columns to match the final result format\n",
    "    # 1. pagecount_desktop_views columns which has the same value as the exisiting 'views' columns\n",
    "    # 2. pagecount_mobile_views which is the value of the 'views' from the corresponding month from mobile data\n",
    "    # 3. pagecount_all_views the sum of mobile and desktop views\n",
    "    desktop_item['pagecount_desktop_views'] = desktop_item['count']\n",
    "    desktop_item['pagecount_mobile_views'] = mobViews\n",
    "    desktop_item['pagecount_all_views'] = desktop_item['count'] + mobViews\n",
    "    pc_total_views['items'].append(desktop_item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a single csv file\n",
    "At this point, our current pageview results are in pv_total_views and page count results are stored in pc_total_views\n",
    "we need to create a single csv file using these two sets of data given [specific format] (https://wiki.communitydata.cc/index.php?title=HCDS_(Fall_2017)/Assignments&action=edit&section=7).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open a file and initialize a csv writer\n",
    "with open(\"en-wikipedia_traffic_200801-201709.csv\", \"w\") as fp:\n",
    "    csv_writer = csv.DictWriter(fp, fieldnames= \\\n",
    "        [\"year\", \"month\", \"pagecount_all_views\", \"pagecount_desktop_views\",\\\n",
    "         \"pagecount_mobile_views\",\"pageview_all_views\",\"pageview_desktop_views\",\"pageview_mobile_views\"])\n",
    "    csv_writer.writeheader()\n",
    "    #Create list of years and months going through both data sets and adding what doesnt already exist\n",
    "    for pc_item in pc_total_views['items']:\n",
    "        added = False\n",
    "        for pv_item in pv_total_views['items']:\n",
    "            if pc_item['year'] == pv_item['year'] and pc_item['month'] == pv_item['month']:\n",
    "                csv_writer.writerow({'year': pc_item['year'], 'month' : pc_item['month'], \\\n",
    "                                     'pagecount_all_views': pc_item['pagecount_all_views'], \\\n",
    "                                     'pagecount_desktop_views' : pc_item['pagecount_desktop_views'], \\\n",
    "                                     'pagecount_mobile_views' : pc_item['pagecount_mobile_views'], \\\n",
    "                                     'pageview_all_views': pv_item['pageview_all_views'], \\\n",
    "                                     'pageview_desktop_views': pv_item['pageview_desktop_views'],\\\n",
    "                                     'pageview_mobile_views': pv_item['pageview_mobile_views']})\n",
    "                added = True\n",
    "                break\n",
    "\n",
    "        if added == False:\n",
    "            csv_writer.writerow({'year': pc_item['year'], 'month': pc_item['month'], \\\n",
    "                                 'pagecount_all_views': pc_item['pagecount_all_views'], \\\n",
    "                                 'pagecount_desktop_views': pc_item['pagecount_desktop_views'], \\\n",
    "                                 'pagecount_mobile_views': pc_item['pagecount_mobile_views'], \\\n",
    "                                 'pageview_all_views': 0, \\\n",
    "                                 'pageview_desktop_views': 0, \\\n",
    "                                 'pageview_mobile_views': 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we have everything ready to begin our analysis on the data.\n",
    "\n",
    "## Step III: Data Analysis\n",
    "\n",
    "This steps is mainly about graphically presenting the processed data in order to display the monthly views data as closly as possible (replicate) the [provided sample graph] (https://wiki.communitydata.cc/upload/thumb/a/a8/PlotPageviewsEN_overlap.png/200px-PlotPageviewsEN_overlap.png)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we can move to plotting step\n",
    "merged_csv = pd.read_csv(\"final_csv.csv\")\n",
    "#print(merged_csv)\n",
    "plt.figure(figsize=(25, 12));\n",
    "\n",
    "df = pd.DataFrame({'year':merged_csv['year'], 'month':merged_csv['month'], 'day':[1]*103})\n",
    "dt = pd.to_datetime(df, format = '%Y%m%')\n",
    "\n",
    "plt.plot(dt[0:103], merged_csv['pagecount_desktop_views'][0:103]/1e6,'g--', label=\"main site\");\n",
    "plt.plot(dt[81:103], merged_csv['pagecount_mobile_views'][81:103]/1e6,'b--', label=\"mobile site\");\n",
    "plt.plot(dt[0:103], merged_csv['pagecount_all_views'][0:103]/1e6,'k--', label=\"total\");\n",
    "\n",
    "plt.legend(['main site', 'mobile site', 'total'], fontsize = 12);\n",
    "\n",
    "plt.plot(dt[90:103], merged_csv['pageview_desktop_views'][90:103]/1e6,'g', label=\"main site\");\n",
    "plt.plot(dt[90:103], merged_csv['pageview_mobile_views'][90:103]/1e6,'b', label=\"mobile site\");\n",
    "plt.plot(dt[90:103], merged_csv['pageview_all_views'][90:103]/1e6,'k', label=\"total\",);\n",
    "\n",
    "plt.title(\"Page Views on English Wikipedia (x 1,000,000)\", fontsize = 15);\n",
    "plt.ylim((0,12000))\n",
    "plt.yticks(fontsize = 14);\n",
    "plt.xticks(fontsize = 14);\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"May 2015: a new pageview definition took effect, which eliminated all crawler traffic.  Dashed lines mark old definition\", fontsize = 14);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the final graph to a file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig('pageviews_english_wikipedia.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
